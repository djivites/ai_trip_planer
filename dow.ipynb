{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3c44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Upgrade crewai-tools\n",
    "install(\"crewai-tools\")\n",
    "\n",
    "# Install YouTube extras\n",
    "install(\"crewai-tools[youtube]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41877e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'YoutubeSearchTool' from 'crewai_tools' (d:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai_tools\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcrewai_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YoutubeSearchTool, YoutubeTranscriptTool\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… YouTube tools installed correctly\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'YoutubeSearchTool' from 'crewai_tools' (d:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai_tools\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from crewai_tools import YoutubeSearchTool, YoutubeTranscriptTool\n",
    "print(\"âœ… YouTube tools installed correctly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b9bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLMs initialized correctly\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LLM' object has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… LLMs initialized correctly\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#test llm\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m response = \u001b[43mllm_groq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mHello, world!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'LLM' object has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "\n",
    "from crewai import LLM\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"groq/llama-3.1-8b-instant\",\n",
    "    temperature=0.4,\n",
    "    max_tokens=180\n",
    ")\n",
    "llm_groq = LLM(\n",
    "    model=\"groq/llama-3.1-8b-instant\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=120\n",
    ")\n",
    "print(\"âœ… LLMs initialized correctly\")\n",
    "#test_llm\n",
    "response = llm_groq.chat(\"Hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc4e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ai_trip_planner\\venv\\Lib\\site-packages\\pydantic\\main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content='Thought:...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Execution Traces</span><span style=\"color: #008080; text-decoration-color: #008080\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ” Detailed execution traces are available!</span>                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">View insights including:</span>                                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Agent decision-making process</span>                                                                              <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Task execution flow and timing</span>                                                                             <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  â€¢ Tool usage details</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mâ•­â”€\u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36m \u001b[0m\u001b[1;36mExecution Traces\u001b[0m\u001b[36m \u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36mâ”€â•®\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[1;36mğŸ” \u001b[0m\u001b[1;36mDetailed execution traces are available!\u001b[0m                                                                    \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[37mView insights including:\u001b[0m                                                                                       \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[94m  â€¢ Agent decision-making process\u001b[0m                                                                              \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[94m  â€¢ Task execution flow and timing\u001b[0m                                                                             \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[94m  â€¢ Tool usage details\u001b[0m                                                                                         \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to view your execution traces? [y/N] (20s timeout): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[34mâ”Œâ”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m Tracing Preference Saved \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â”\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m                                                                             \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m  Info: Tracing has been disabled.                                           \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m                                                                             \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m  Your preference has been saved. Future Crew/Flow executions will not       \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m  collect traces.                                                            \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m                                                                             \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m  To enable tracing later, do any one of these:                              \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m  â€¢ Set tracing=True in your Crew/Flow code                                  \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m  â€¢ Set CREWAI_TRACING_ENABLED=true in your project's .env file              \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m  â€¢ Run: crewai traces enable                                                \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ”‚\u001b[0m                                                                             \u001b[34mâ”‚\u001b[0m\n",
      "\u001b[34mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"groq/llama-3.1-8b-instant\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=120\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    role=\"Tester\",\n",
    "    goal=\"Respond politely\",\n",
    "    backstory=\"You test LLM connectivity.\",\n",
    "    tools=[],\n",
    "    llm=llm,\n",
    "    max_retry_limit=0\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    description=\"Say hello in one sentence.\",\n",
    "    agent=agent,\n",
    "    expected_output=\"One short greeting sentence.\"\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    process=\"sequential\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44447d70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Google Gen AI native provider not available, to install: uv add \"crewai[google-genai]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcrewai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent, Task, Crew, LLM\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini/gemini-1.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m agent = Agent(\n\u001b[32m      6\u001b[39m     role=\u001b[33m\"\u001b[39m\u001b[33mTester\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     goal=\u001b[33m\"\u001b[39m\u001b[33mTest Gemini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     backstory=\u001b[33m\"\u001b[39m\u001b[33mYou test Gemini connectivity.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     llm=llm\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m task = Task(\n\u001b[32m     13\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mSay hello in one sentence.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     agent=agent\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\llm.py:397\u001b[39m, in \u001b[36mLLM.__new__\u001b[39m\u001b[34m(cls, model, is_litellm, **kwargs)\u001b[39m\n\u001b[32m    394\u001b[39m     use_native = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    395\u001b[39m     model_string = model\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m native_class = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_native_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m use_native \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m native_class \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_litellm \u001b[38;5;129;01mand\u001b[39;00m provider \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_NATIVE_PROVIDERS:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    400\u001b[39m         \u001b[38;5;66;03m# Remove 'provider' from kwargs if it exists to avoid duplicate keyword argument\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\llm.py:553\u001b[39m, in \u001b[36mLLM._get_native_provider\u001b[39m\u001b[34m(cls, provider)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m AzureCompletion\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider == \u001b[33m\"\u001b[39m\u001b[33mgoogle\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m provider == \u001b[33m\"\u001b[39m\u001b[33mgemini\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcrewai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproviders\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompletion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiCompletion\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GeminiCompletion\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider == \u001b[33m\"\u001b[39m\u001b[33mbedrock\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\llms\\providers\\gemini\\completion.py:30\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerateContentResponse\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     31\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mGoogle Gen AI native provider not available, to install: uv add \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcrewai[google-genai]\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     32\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mGeminiCompletion\u001b[39;00m(BaseLLM):\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Google Gemini native completion implementation.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    This class provides direct integration with the Google Gen AI Python SDK,\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    offering native function calling, streaming support, and proper Gemini formatting.\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Google Gen AI native provider not available, to install: uv add \"crewai[google-genai]\""
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "llm = LLM(model=\"gemini/gemini-1.5-flash\")\n",
    "\n",
    "agent = Agent(\n",
    "    role=\"Tester\",\n",
    "    goal=\"Test Gemini\",\n",
    "    backstory=\"You test Gemini connectivity.\",\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    description=\"Say hello in one sentence.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "crew = Crew(agents=[agent], tasks=[task])\n",
    "print(crew.kickoff())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0025de96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "litellm.NotFoundError: GeminiException - {\n  \"error\": {\n    \"code\": 404,\n    \"message\": \"models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\",\n    \"status\": \"NOT_FOUND\"\n  }\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\llms\\vertex_ai\\gemini\\vertex_and_google_ai_studio_gemini.py:2657\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   2656\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2657\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   2658\u001b[39m     response.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:979\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    978\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mstatus_code\u001b[39m\u001b[33m\"\u001b[39m, e.response.status_code)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:961\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    960\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.send(req, stream=stream)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '404 Not Found' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyChMhm7eX9xbmw33qBrpkzWfpSYP5b60ZA'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mVertexAIError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\main.py:3192\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   3191\u001b[39m     new_params = safe_deep_copy(optional_params \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[32m-> \u001b[39m\u001b[32m3192\u001b[39m     response = \u001b[43mvertex_chat_completion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   3193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3197\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   3199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_get_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3206\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   3209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3214\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mvertex_ai\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\llms\\vertex_ai\\gemini\\vertex_and_google_ai_studio_gemini.py:2661\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   2660\u001b[39m     error_code = err.response.status_code\n\u001b[32m-> \u001b[39m\u001b[32m2661\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m VertexAIError(\n\u001b[32m   2662\u001b[39m         status_code=error_code,\n\u001b[32m   2663\u001b[39m         message=err.response.text,\n\u001b[32m   2664\u001b[39m         headers=err.response.headers,\n\u001b[32m   2665\u001b[39m     )\n\u001b[32m   2666\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException:\n",
      "\u001b[31mVertexAIError\u001b[39m: {\n  \"error\": {\n    \"code\": 404,\n    \"message\": \"models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\",\n    \"status\": \"NOT_FOUND\"\n  }\n}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     15\u001b[39m task = Task(\n\u001b[32m     16\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mSay hello in one sentence.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     expected_output=\u001b[33m\"\u001b[39m\u001b[33mA single friendly greeting sentence.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     agent=agent\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m crew = Crew(\n\u001b[32m     22\u001b[39m     agents=[agent],\n\u001b[32m     23\u001b[39m     tasks=[task]\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcrew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\crew.py:714\u001b[39m, in \u001b[36mCrew.kickoff\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    711\u001b[39m inputs = prepare_kickoff(\u001b[38;5;28mself\u001b[39m, inputs)\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.sequential:\n\u001b[32m--> \u001b[39m\u001b[32m714\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.hierarchical:\n\u001b[32m    716\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._run_hierarchical_process()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\crew.py:1073\u001b[39m, in \u001b[36mCrew._run_sequential_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> CrewOutput:\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\crew.py:1159\u001b[39m, in \u001b[36mCrew._execute_tasks\u001b[39m\u001b[34m(self, tasks, start_index, was_replayed)\u001b[39m\n\u001b[32m   1156\u001b[39m     futures.clear()\n\u001b[32m   1158\u001b[39m context = \u001b[38;5;28mself\u001b[39m._get_context(task, task_outputs)\n\u001b[32m-> \u001b[39m\u001b[32m1159\u001b[39m task_output = \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1164\u001b[39m task_outputs.append(task_output)\n\u001b[32m   1165\u001b[39m \u001b[38;5;28mself\u001b[39m._process_task_result(task, task_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\task.py:458\u001b[39m, in \u001b[36mTask.execute_sync\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_sync\u001b[39m(\n\u001b[32m    452\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    453\u001b[39m     agent: BaseAgent | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    454\u001b[39m     context: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    455\u001b[39m     tools: \u001b[38;5;28mlist\u001b[39m[BaseTool] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    456\u001b[39m ) -> TaskOutput:\n\u001b[32m    457\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\task.py:695\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    693\u001b[39m \u001b[38;5;28mself\u001b[39m.end_time = datetime.datetime.now()\n\u001b[32m    694\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskFailedEvent(error=\u001b[38;5;28mstr\u001b[39m(e), task=\u001b[38;5;28mself\u001b[39m))  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\task.py:626\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28mself\u001b[39m.processed_by_agents.add(agent.role)\n\u001b[32m    625\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskStartedEvent(context=context, task=\u001b[38;5;28mself\u001b[39m))  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrails \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrail:\n\u001b[32m    633\u001b[39m     pydantic_output, json_output = \u001b[38;5;28mself\u001b[39m._export_output(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\agent\\core.py:416\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mlitellm\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    408\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    409\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    410\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    414\u001b[39m         ),\n\u001b[32m    415\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    417\u001b[39m \u001b[38;5;28mself\u001b[39m._times_executed += \u001b[32m1\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._times_executed > \u001b[38;5;28mself\u001b[39m.max_retry_limit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\agent\\core.py:394\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    390\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._execute_with_timeout(\n\u001b[32m    391\u001b[39m             task_prompt, task, \u001b[38;5;28mself\u001b[39m.max_execution_time\n\u001b[32m    392\u001b[39m         )\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_without_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    397\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    398\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    399\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    403\u001b[39m         ),\n\u001b[32m    404\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\agent\\core.py:490\u001b[39m, in \u001b[36mAgent._execute_without_timeout\u001b[39m\u001b[34m(self, task_prompt, task)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agent_executor:\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAgent executor is not initialized.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mask_for_human_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:196\u001b[39m, in \u001b[36mCrewAgentExecutor.invoke\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28mself\u001b[39m.ask_for_human_input = \u001b[38;5;28mbool\u001b[39m(inputs.get(\u001b[33m\"\u001b[39m\u001b[33mask_for_human_input\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     formatted_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[32m    198\u001b[39m     \u001b[38;5;28mself\u001b[39m._printer.print(\n\u001b[32m    199\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mAgent failed to reach a final answer. This is likely a bug - please report it.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    200\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    201\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:308\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mlitellm\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    307\u001b[39m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_context_length_exceeded(e):\n\u001b[32m    310\u001b[39m         handle_context_length(\n\u001b[32m    311\u001b[39m             respect_context_window=\u001b[38;5;28mself\u001b[39m.respect_context_window,\n\u001b[32m    312\u001b[39m             printer=\u001b[38;5;28mself\u001b[39m._printer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    316\u001b[39m             i18n=\u001b[38;5;28mself\u001b[39m._i18n,\n\u001b[32m    317\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:237\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    235\u001b[39m enforce_rpm_limit(\u001b[38;5;28mself\u001b[39m.request_within_rpm_limit)\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m answer = \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprinter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_printer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py:276\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer, from_task, from_agent, response_model, executor_context)\u001b[39m\n\u001b[32m    268\u001b[39m     answer = llm.call(\n\u001b[32m    269\u001b[39m         messages,\n\u001b[32m    270\u001b[39m         callbacks=callbacks,\n\u001b[32m   (...)\u001b[39m\u001b[32m    273\u001b[39m         response_model=response_model,\n\u001b[32m    274\u001b[39m     )\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[32m    278\u001b[39m     printer.print(\n\u001b[32m    279\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mReceived None or empty response from LLM call.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    280\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    281\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py:268\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer, from_task, from_agent, response_model, executor_context)\u001b[39m\n\u001b[32m    265\u001b[39m     messages = executor_context.messages\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     answer = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\llm.py:1677\u001b[39m, in \u001b[36mLLM.call\u001b[39m\u001b[34m(self, messages, tools, callbacks, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m   1668\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._handle_streaming_response(\n\u001b[32m   1669\u001b[39m         params=params,\n\u001b[32m   1670\u001b[39m         callbacks=callbacks,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1674\u001b[39m         response_model=response_model,\n\u001b[32m   1675\u001b[39m     )\n\u001b[32m   1676\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1677\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_non_streaming_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mavailable_functions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mavailable_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1687\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._invoke_after_llm_call_hooks(\n\u001b[32m   1688\u001b[39m         messages, result, from_agent\n\u001b[32m   1689\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\crewai\\llm.py:1146\u001b[39m, in \u001b[36mLLM._handle_non_streaming_response\u001b[39m\u001b[34m(self, params, callbacks, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m   1144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response_model:\n\u001b[32m   1145\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mresponse_model\u001b[39m\u001b[33m\"\u001b[39m] = response_model\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m response = \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response,\u001b[33m\"\u001b[39m\u001b[33musage\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.usage, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m response.usage:\n\u001b[32m   1149\u001b[39m     usage_info = response.usage\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\utils.py:1653\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1650\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1651\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1652\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1653\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\utils.py:1517\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1517\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1518\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1520\u001b[39m     kwargs=kwargs,\n\u001b[32m   1521\u001b[39m     call_type=call_type,\n\u001b[32m   1522\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\main.py:4159\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   4156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   4157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   4158\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4159\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4162\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2346\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2345\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2346\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2348\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ai_trip_planner\\venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:1401\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_exception.status_code == \u001b[32m404\u001b[39m:\n\u001b[32m   1400\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[32m   1402\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcustom_llm_provider.capitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mException - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1403\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m   1404\u001b[39m         model=model,\n\u001b[32m   1405\u001b[39m     )\n\u001b[32m   1406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_exception.status_code == \u001b[32m408\u001b[39m:\n\u001b[32m   1407\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mNotFoundError\u001b[39m: litellm.NotFoundError: GeminiException - {\n  \"error\": {\n    \"code\": 404,\n    \"message\": \"models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\",\n    \"status\": \"NOT_FOUND\"\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-1.5-flash\",\n",
    "    provider=\"litellm\"\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    role=\"Tester\",\n",
    "    goal=\"Test Gemini via LiteLLM\",\n",
    "    backstory=\"You test Gemini connectivity.\",\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    description=\"Say hello in one sentence.\",\n",
    "    expected_output=\"A single friendly greeting sentence.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task]\n",
    ")\n",
    "\n",
    "print(crew.kickoff())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d78b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there, it's great to connect!\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-2.5-flash\",\n",
    "    provider=\"litellm\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=150,        # SMALL\n",
    ")\n",
    "llm_groq = LLM(\n",
    "            model=\"groq/llama-3.1-8b-instant\",\n",
    "            temperature=0.2,\n",
    "            max_tokens=250\n",
    "        )\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    role=\"Tester\",\n",
    "    goal=\"Test Gemini via LiteLLM\",\n",
    "    backstory=\"You test Gemini connectivity.\",\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    description=\"Say hello in one sentence.\",\n",
    "    expected_output=\"A single friendly greeting sentence.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task]\n",
    ")\n",
    "\n",
    "print(crew.kickoff())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7282ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heeloo\n"
     ]
    }
   ],
   "source": [
    "print(\"heeloo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5567a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", package\n",
    "    ])\n",
    "\n",
    "install(\"litellm[proxy]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a093ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
